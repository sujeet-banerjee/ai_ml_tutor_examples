{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3KDikoDwY8v"
   },
   "source": [
    "# Import necessary libraries"
   ],
   "id": "a721df052bf8a4f1"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VvxOowgOTndB",
    "ExecuteTime": {
     "end_time": "2025-12-09T10:09:57.532546Z",
     "start_time": "2025-12-09T10:09:44.386360Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow_datasets as tfds\n",
    "import pathlib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set the default figure size for matplotlib\n",
    "plt.rcParams['figure.figsize'] = (7,7) # Make the figures a bit bigger"
   ],
   "id": "4da9f04433f81b82",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3yEVbRlnlDf"
   },
   "source": [
    "# Load data and preprocess it"
   ],
   "id": "2e179ac3cf3968f7"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kSeCVHn-hcF"
   },
   "source": [
    "## Upload the data to drive:\n",
    "Download the dataset from Brigthspace, and upload it to the content folder in Google Colab.\n"
   ],
   "id": "18443ce5a9cb97a4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eibrnWSdM1U"
   },
   "source": [
    "###Option 1: To avoid having to upload the dataset every time, you can upload the dataset to your google drive, and then connect this virtual machine to your drive, and make a copy of your data"
   ],
   "id": "f963c8c2fc2b3187"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IJnHQ6_bc5t"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "id": "fc4784ca4e4d423b"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBNEzxhBovZR"
   },
   "source": [
    "Replace the path /content/drive/MyDrive/Work/2025-CS3002/BrainTumorDataset.zip with your actual path where you copied the dataset in your drive."
   ],
   "id": "c10c1526e09e3f0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T10:10:42.035234Z",
     "start_time": "2025-12-09T10:10:41.968667Z"
    }
   },
   "cell_type": "code",
   "source": "!pwd",
   "id": "7fe54269c889ad18",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXdFEw-Zc941"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/Work/2025-CS3002/BrainTumorDataset.zip /content/"
   ],
   "id": "2daeca699ac89673"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32VoQ0e8dqUi"
   },
   "source": [
    "###Option 2: Upload the zip archive in the Files section of your virtual machine, under /content/"
   ],
   "id": "ff9a6f1498a3a2ab"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbM9r9kgd1Pb"
   },
   "source": [
    "###After the data is loaded, let's start processing it."
   ],
   "id": "cbf19d5876591657"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7VzZUvK_DKA"
   },
   "outputs": [],
   "source": [
    "# After you have copied the data locally, point the dataset_url to the local path\n",
    "dataset_url = '/content/BrainTumorDataset.zip'"
   ],
   "id": "629be9773cd52a2a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDUGb9HbgYGy"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to your local zip file\n",
    "zip_path = dataset_url\n",
    "\n",
    "# Path where you want to extract\n",
    "out_path = \"/content/\"\n",
    "\n",
    "# Extract\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(out_path)\n",
    "\n",
    "print(\"Extraction complete. Files are in:\", out_path)\n"
   ],
   "id": "aedea13e4043a6b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PjaJOFXbJ61"
   },
   "outputs": [],
   "source": [
    "# Create a 'pathlib.Path' object for the downloaded archive\n",
    "# Pathlib module offers classes representing filesystem paths with semantics\n",
    "# appropriate for different operating systems.\n",
    "# data_dir = pathlib.Path(archive).with_suffix('')\n",
    "\n",
    "extract_dir = pathlib.Path(zip_path).with_suffix('')\n",
    "# Now use Pathlib for further work\n",
    "data_dir = pathlib.Path(extract_dir)\n",
    "\n",
    "print(\"Data directory is:\", data_dir)"
   ],
   "id": "479de2c0585d0ddb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IxTLf2jbxe2"
   },
   "outputs": [],
   "source": [
    "# Count the number of images in a specific directory\n",
    "image_count = len(list(data_dir.glob('./Training/glioma/*.jpg')))\n",
    "print(image_count)"
   ],
   "id": "4575db722ae155a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qUU_NoKxtHp"
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "# Brain tumour dataset is split into train, validation and test folders. Inside those folders you will\n",
    "# find additional folders: glioma, pituitary, notumor. You can explore the folders using\n",
    "# 'Files' tab from the right hand side.\n",
    "# Tip: use the len() function\n",
    "\n",
    "# 1a. How many images do we have in training for positive glaucoma? How many for negative glaucoma?\n",
    "\n",
    "\n",
    "# 1b. How about in the testing set?\n",
    "\n",
    "\n",
    "# 1c. How about in the validation set?\n",
    "\n",
    "\n",
    "# Q. Is the dataset balanced or not?\n",
    "\n",
    "# END YOUR CODE HERE"
   ],
   "id": "f197658378374566"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wyaZFcvpxwL"
   },
   "outputs": [],
   "source": [
    "# Create a list of file paths for glaucoma images\n",
    "positive_images = list(data_dir.glob('Training/glioma/*'))\n",
    "# Open and display the first glaucoma image in the list\n",
    "PIL.Image.open(str(positive_images[0]))"
   ],
   "id": "5e644897ceb0285b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtx3hXaEyqK4"
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "# 2. Display a glioma image from the validation dataset\n",
    "# Create a list of file paths for glioma images\n",
    "\n",
    "\n",
    "# Open and display the first glioma image in the list\n",
    "\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ],
   "id": "338eaaf710d6baeb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srQii0Q4idqO"
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "# 2. Display a normal image from the validation dataset\n",
    "\n",
    "# Create a list of file paths for the no tumour images\n",
    "\n",
    "\n",
    "# Open and display the first  image in the list\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ],
   "id": "94ad360cf0d36f7e"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrEz4zkbE8yq"
   },
   "source": [
    "# Define a deep learning model that will learn the differences between glioma, pituitary and normal brain images\n"
   ],
   "id": "4abe07f6f04d68da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGncT3F_qGKe"
   },
   "outputs": [],
   "source": [
    "# Define batch size and image dimensions for training\n",
    "\n",
    "# BEGIN YOUR CODE HERE\n",
    "# The batch size is the number of samples processed before the model is updated.\n",
    "# Choose an appropriate batch size.\n",
    "\n",
    "# batch_size = TODO\n",
    "\n",
    "\n",
    "# What is the resolution of the images?\n",
    "# Specify the size to resize images to after they are read from disk.\n",
    "# Since the pipeline processes batches of images that must all have the same size, this must be provided.\n",
    "\n",
    "# img_height = TODO\n",
    "# img_width = TODO\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ],
   "id": "29ee4a5e1ba60e94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rwd_T8s0Exo"
   },
   "outputs": [],
   "source": [
    "train_data_dir  = os.path.join(data_dir,'Training')\n",
    "valid_data_dir = os.path.join(data_dir,'Validation')\n",
    "test_data_dir = os.path.join(data_dir,'Testing')"
   ],
   "id": "20d23d2cf8ecc575"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6e8Dbw6p8fL"
   },
   "outputs": [],
   "source": [
    "# Create a TensorFlow image dataset from a directory\n",
    "# BEGIN YOUR CODE HERE\n",
    "# Use the function tf.keras.utils.image_dataset_from_directory to load\n",
    "# the training dataset: https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n",
    "# 1. First argument is your training directory folder (train_data_dir),\n",
    "# 2. Do NOT use validation_split since we only want a training set,\n",
    "# 3. You can set a seed such that when you repeat experiments you get similar results, e.g. seed=123,\n",
    "# 4. For image size, use the img_height and img_width variables you defined previously,\n",
    "# 5. For batch size, use the batch_size variable you defined earlier in the code.\n",
    "# tf.keras.utils.image_dataset_from_directory(\n",
    "#     directory,\n",
    "#     seed=123,\n",
    "#     image_size=(height, width),\n",
    "#     batch_size=-1,\n",
    "#     shuffle=False\n",
    "# )\n",
    "# Example:\n",
    "\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ],
   "id": "ae56260e4eae7bd9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hI684wjqcHg"
   },
   "outputs": [],
   "source": [
    "# Create a layer to normalise pixel values to the [0, 1] range.\n",
    "# By default, when you load an image, each pixel value will have a value between 0-255\n",
    "# but, in neural networks, we need as input normalised values in [0,1] interval.\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ],
   "id": "3ef1fdd91a9a08e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxTxKXY5qhKK"
   },
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image), first_image[0][0])"
   ],
   "id": "9097b35906813868"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXebzJrEqm7K"
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "# Define the number of classes in the classification problem\n",
    "# How many classes do we have in this dataset?\n",
    "# num_classes = TODO\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ],
   "id": "c1b4934508c1570e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wm-uZPDWqlR9"
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "# Define a tensorflow model using the tf.keras.Sequential class: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "# The last layer should be a Dense layer with the number of output neurons num_classes\n",
    "# Use as a starting point the tf.keras.Sequential model defined for the MNIST problem.\n",
    "# See Lab-DeepLearning-ImageClassification.\n",
    "# For the first Conv2D layer, you are not required to specify the input shape. If that\n",
    "# parameter is not given, tensorflow library will infer the size of the input when\n",
    "# you fit the model, so it will depend on the size of the dataset.\n",
    "# Important: change the output of the last Dense layer to match the number of classes for this problem.\n",
    "# If you don't use any of the Dropout layers what accuracy do you get?\n",
    "# What accuracy do you get with the Dropout layers?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE\n",
    "\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy']) # Monitor accuracy and F1 score during training\n",
    "\n"
   ],
   "id": "d2dcfbd64fb8e68e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJlSQVJi2EoX"
   },
   "outputs": [],
   "source": [
    "# Extract training labels\n",
    "y_train = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# TIP: Search how you can use the class weights during training to improve your results"
   ],
   "id": "9a9f717b3f03acd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9JHh90rjD6K"
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "# Train the model on the provided dataset for a specified number of epochs\n",
    "# Modify the network architecture such that you maximise the accuracy.\n",
    "# Tip: aim to get an accuracy of at least 70% on the training set.\n",
    "# For this, you can use the function fit, as in model.fit(...)\n",
    "# The first argument is the train_ds variable defined above.\n",
    "# This variable contains both the x (data - glaucoma and normal images) and y\n",
    "# (labels - glaucoma vs normal).\n",
    "# Start training using 5 epochs. What is the accuracy you get?\n",
    "# How about if you increase the number of epochs?\n",
    "# Use as validation_data the val_ds variable you defined previously\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ],
   "id": "e5c4ffe09cd284ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhgtq6HYhS9D"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d  # for smoothing\n",
    "\n",
    "# function to plot loss/accuracy with trend lines\n",
    "def plot_loss_accuracy(history, smooth_sigma=2):\n",
    "    # Extract loss and accuracy values\n",
    "    loss_values = history.history['loss']\n",
    "    acc_values = history.history['accuracy']\n",
    "\n",
    "    # Validation (if available)\n",
    "    val_loss = history.history.get('val_loss')\n",
    "    val_acc = history.history.get('val_accuracy')\n",
    "\n",
    "    epochs = np.arange(1, len(loss_values) + 1)\n",
    "\n",
    "    # --- Plot Training & Validation Loss ---\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss_values, marker='o', linestyle='-', color='b', alpha=0.5, label='Training Loss')\n",
    "    plt.plot(epochs, gaussian_filter1d(loss_values, sigma=smooth_sigma), color='b', linewidth=2, label='Trend (Train)')\n",
    "\n",
    "    if val_loss is not None:\n",
    "        plt.plot(epochs, val_loss, marker='x', linestyle='--', color='r', alpha=0.5, label='Validation Loss')\n",
    "        plt.plot(epochs, gaussian_filter1d(val_loss, sigma=smooth_sigma), color='r', linewidth=2, label='Trend (Val)')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # --- Plot Training & Validation Accuracy ---\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, acc_values, marker='o', linestyle='-', color='g', alpha=0.5, label='Training Accuracy')\n",
    "    plt.plot(epochs, gaussian_filter1d(acc_values, sigma=smooth_sigma), color='g', linewidth=2, label='Trend (Train)')\n",
    "\n",
    "    if val_acc is not None:\n",
    "        plt.plot(epochs, val_acc, marker='x', linestyle='--', color='orange', alpha=0.5, label='Validation Accuracy')\n",
    "        plt.plot(epochs, gaussian_filter1d(val_acc, sigma=smooth_sigma), color='orange', linewidth=2, label='Trend (Val)')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "84e1a068caf5a80b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0-micMEnY9m"
   },
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ],
   "id": "2ba2b3b3469914c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaRpL01W4u_2"
   },
   "outputs": [],
   "source": [
    "# Let's load the testing dataset\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_data_dir,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False   # ðŸ”‘ Ensure labels line up with predictions\n",
    ")"
   ],
   "id": "24b85a2b71ca6977"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2D3V6r55SGe"
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "# What is the loss and accuracy on the Testing dataset?\n",
    "# Compute and plot the confusion matrix on the test dataset\n",
    "# Tip: instead of (x_test, y_test) we used in the lab last week, you can use\n",
    "# directly test_ds which contains both data and labels\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\n",
    "# When you print the output of the evaluate function is run, it will return both\n",
    "# the loss and accuracy, maybe in a  format like [loss_value, accuracy_value]\n",
    "# print(\"Model accuracy on the test set is:\", model.evaluate(test_ds))\n",
    "# Display the confusion matrix, precision, recall and f1-score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ],
   "id": "6783af0e7170a3df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JO9Z1pqy6M9i"
   },
   "outputs": [],
   "source": [
    "# Try to improve the model such that it performs well on both training and testing datasets."
   ],
   "id": "2b2bba77b9e1aef1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
